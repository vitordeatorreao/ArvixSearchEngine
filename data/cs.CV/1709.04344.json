{
    "paper_authors_list": [
        "Zhuang, Lixue", 
        "Xu, Yi", 
        "Ni, Bingbing", 
        "Xu, Hongteng"
    ], 
    "paper_comments": "8 pages", 
    "paper_page_url": "https://arxiv.org/abs/1709.04344", 
    "paper_abstract": "How to effectively approximate real-valued parameters with binary codes plays\na central role in neural network binarization. In this work, we reveal an\nimportant fact that binarizing different layers has a widely-varied effect on\nthe compression ratio of network and the loss of performance. Based on this\nfact, we propose a novel and flexible neural network binarization method by\nintroducing the concept of layer-wise priority which binarizes parameters in\ninverse order of their layer depth. In each training step, our method selects a\nspecific network layer, minimizes the discrepancy between the original\nreal-valued weights and its binary approximations, and fine-tunes the whole\nnetwork accordingly. During the iteration of the above process, it is\nsignificant that we can flexibly decide whether to binarize the remaining\nfloating layers or not and explore a trade-off between the loss of performance\nand the compression ratio of model. The resulting binary network is applied for\nefficient pedestrian detection. Extensive experimental results on several\nbenchmarks show that under the same compression ratio, our method achieves much\nlower miss rate and faster detection speed than the state-of-the-art neural\nnetwork binarization method.", 
    "paper_subjects": null, 
    "paper_code": "1709.04344", 
    "paper_submission_date": "2017/09/13", 
    "paper_title": "Flexible Network Binarization with Layer-wise Priority"
}